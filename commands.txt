1) Alphabet generator from csv.

python3 training/deepspeech_training/util/check_characters.py -alpha -csv ~/clips/train.csv,~/clips/dev.csv,~/clips/test.csv > Alphabet.txt

2) Training.

python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir ~/Checkpoints --epochs 500 --train_files ~/clips-rwn-10-dB-Noisy/train.csv --dev_files ~/clips-rwn-10-dB-Noisy/dev.csv --test_files ~/clips-rwn-10-dB-Noisy/test.csv --export_tflite --export_dir ~/Model --train_batch_size 32 --dev_batch_size 32 --test_batch_size 32 --alphabet_config_path ~/Alphabet.txt --use_allow_growth true --train_cudnn true

3) Transfer-learning.

python3 DeepSpeech.py --drop_source_layers 1 --alphabet_config_path ~/Alphabet.txt --save_checkpoint_dir ~/Checkpoints --load_checkpoint_dir ~/Checkpoints --train_files ~/clips-rwn-10-dB-Noisy/train.csv --dev_files ~/clips-rwn-10-dB-Noisy/dev.csv --test_files ~/clips-rwn-10-dB-Noisy/test.csv --export_tflite --export_dir ~/Model --train_batch_size 32 --dev_batch_size 32 --test_batch_size 32 --epochs 500 --use_allow_growth true --train_cudnn true

4) Generate scorer file.

The scorer is used to compute the likelihood (also called a score, hence the name “scorer”) of sequences of words or characters in the output, to guide the decoder towards more likely results. This improves accuracy significantly.
At decoding time, if using an external scorer, it MUST be word based and MUST be built using the same alphabet file used for training. Word based means the text corpus used to build the scorer should contain words separated by whitespace. 

Generate KenLM language model.

cd data/lm

python3 generate_lm.py --input_txt ~/all_data.txt --output_dir ~/Model --top_k 500000 --kenlm_bins /home/varuzhan/kenlm/build/bin/ --arpa_order 5 --max_arpa_memory "85%" --arpa_prune "0|0|1" --binary_a_bits 255 --binary_q_bits 8 --binary_type trie
--discount_fallback

Generate scorer file.

./generate_scorer_package --alphabet ~/Alphabet.txt --lm ~/Model/lm.binary --vocab ~/Model/vocab-500000.txt --package ~/Model/kenlm.scorer --default_alpha 2.6175607838793176 --default_beta 3.362191052993364

To find good default values for alpha and beta, first generate a package with any value set for default alpha and beta flags. For this step, it doesn’t matter what values you use, as they’ll be overridden by lm_optimizer.py later. Then, use lm_optimizer.py with this scorer file to find good alpha and beta values. Finally, use generate_scorer_package again, this time with the new values.

CUDA_VISIBLE_DEVICES=1 python3 lm_optimizer.py --test_files ~/clips/validated.csv --checkpoint_dir ~/Checkpoints --scorer ~/Model/kenlm.scorer --alphabet_config_path ~/Alphabet.txt

5) Important notes.

5.1) Validate function.

Some importers might require additional code to properly handled your locale-specific requirements. Such handling is dealt with --validate_label_locale flag that allows you to source out-of-tree Python script that defines a validate_label function. Please refer to util/importers.py for implementation example of that function. If you don’t provide this argument, the default validate_label function will be used. This one is only intended for English language, so you might have consistency issues in your data for other languages.

For example, in order to use a custom validation function that disallows any sample with “a” in its transcript, and lower cases everything else, you could put the following code in a file called my_validation.py and then use --validate_label_locale my_validation.py:

def validate_label(label):
    if 'a' in label: # disallow labels with 'a'
        return None
    return label.lower() # lower case valid labels
If you’ve run the old importers (in util/importers/), they could have removed source files that are needed for the new importers to run. In that case, simply remove the extracted folders and let the importer extract and process the dataset from scratch, and things should work.

5.2) Making a mmap-able model for inference

The output_graph.pb model file generated in the above step will be loaded in memory to be dealt with when running inference. This will result in extra loading time and memory consumption. One way to avoid this is to directly read data from the disk.

Download the tool.
python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target mmap

Run.
mmap/convert_graphdef_memmapped_format --in_graph=~/Model/deepspeech-0.9.3-models.pb --out_graph=~/Model/deepspeech-0.9.3-models.pbmm

5.3) ffmpeg.

ffmpeg -i input.wav -vn -ar 44100 -ac 2 -b:a 192k output.mp3

Explanation of the used arguments in this example:
-i - input file.

-vn - Disable video, to make sure no video (including album cover image) is included if the source would be a video file.

-ar - Set the audio sampling frequency. For output streams it is set by default to the frequency of the corresponding input stream. For input streams this option only makes sense for audio grabbing devices and raw demuxers and is mapped to the corresponding demuxer options.

-ac - Set the number of audio channels. For output streams it is set by default to the number of input audio channels. For input streams this option only makes sense for audio grabbing devices and raw demuxers and is mapped to the corresponding demuxer options. So used here to make sure it is stereo (2 channels).

-b:a - Converts the audio bitrate to be exact 192kbit per second.

5.4) CUDA and cuDNN installation.

sudo sh cuda_10.0.130_410.48_linux.run --override

tar -xzvf cudnn-10.0-linux-x64-v7.6.2.24.tgz

sudo cp cuda/include/cudnn*.h /usr/local/cuda/include

sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64

sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*





